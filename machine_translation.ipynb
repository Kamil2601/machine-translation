{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import load_dataset, SpecialTokens\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from models_2 import EncoderGRU, DecoderGRU, Seq2seq\n",
    "from train import Trainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 45660.89it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 42633.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train_size = 10000\n",
    "val_size = 1000\n",
    "train_data, human_vocab, machine_vocab = load_dataset(train_size)\n",
    "val_data, _, _ = load_dataset(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '?': 1,\n",
       " ' ': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " 'a': 15,\n",
       " 'b': 16,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'h': 22,\n",
       " 'i': 23,\n",
       " 'j': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'y': 36}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '>': 1,\n",
       " '<': 2,\n",
       " '-': 3,\n",
       " '0': 4,\n",
       " '1': 5,\n",
       " '2': 6,\n",
       " '3': 7,\n",
       " '4': 8,\n",
       " '5': 9,\n",
       " '6': 10,\n",
       " '7': 11,\n",
       " '8': 12,\n",
       " '9': 13}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4/9/97', '>1997-04-09<'),\n",
       " ('9/8/83', '>1983-09-08<'),\n",
       " ('8/7/97', '>1997-08-07<'),\n",
       " ('4/2/02', '>2002-04-02<'),\n",
       " ('1/9/12', '>2012-01-09<'),\n",
       " ('7/3/09', '>2009-07-03<'),\n",
       " ('9/9/84', '>1984-09-09<'),\n",
       " ('2/2/00', '>2000-02-02<'),\n",
       " ('1/1/79', '>1979-01-01<'),\n",
       " ('4/7/92', '>1992-04-07<'),\n",
       " ('8/7/81', '>1981-08-07<'),\n",
       " ('8/3/80', '>1980-08-03<'),\n",
       " ('6/7/07', '>2007-06-07<'),\n",
       " ('7/3/09', '>2009-07-03<'),\n",
       " ('1/8/95', '>1995-01-08<'),\n",
       " ('1/2/71', '>1971-01-02<'),\n",
       " ('7/2/00', '>2000-07-02<'),\n",
       " ('8/4/98', '>1998-08-04<'),\n",
       " ('4/3/78', '>1978-04-03<'),\n",
       " ('7/3/95', '>1995-07-03<')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4/7/24', '>2024-04-07<'),\n",
       " ('5/3/70', '>1970-05-03<'),\n",
       " ('8/2/77', '>1977-08-02<'),\n",
       " ('9/7/73', '>1973-09-07<'),\n",
       " ('2/9/97', '>1997-02-09<'),\n",
       " ('7/3/96', '>1996-07-03<'),\n",
       " ('1/1/73', '>1973-01-01<'),\n",
       " ('6/30/82', '>1982-06-30<'),\n",
       " ('8 06 22', '>2022-06-08<'),\n",
       " ('8/28/98', '>1998-08-28<'),\n",
       " ('8/11/96', '>1996-08-11<'),\n",
       " ('4/10/89', '>1989-04-10<'),\n",
       " ('9 06 94', '>1994-06-09<'),\n",
       " ('4/28/93', '>1993-04-28<'),\n",
       " ('2/17/02', '>2002-02-17<'),\n",
       " ('6 04 98', '>1998-04-06<'),\n",
       " ('7/22/10', '>2010-07-22<'),\n",
       " ('9/30/72', '>1972-09-30<'),\n",
       " ('1/18/84', '>1984-01-18<'),\n",
       " ('2/13/92', '>1992-02-13<')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def _get_char(self, ind):\n",
    "        if isinstance(ind, torch.Tensor):\n",
    "            return self.inv_vocab[ind.item()]\n",
    "        else:\n",
    "            return self.inv_vocab[ind]\n",
    "\n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {v:k for k,v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def str_to_ind(self, str):\n",
    "        return [self.vocab[c] for c in str]\n",
    "    \n",
    "    def ind_to_str(self, ind):\n",
    "        return ''.join([self._get_char(i) for i in ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/9/97\n",
      "[9, 4, 14, 4, 14, 12]\n",
      "4/9/97\n"
     ]
    }
   ],
   "source": [
    "test = Lang(human_vocab)\n",
    "date = train_data[0][0]\n",
    "print(date)\n",
    "translated_date = test.str_to_ind(date)\n",
    "print(translated_date)\n",
    "reversed_translation = test.ind_to_str(translated_date)\n",
    "print(reversed_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationTrainingDataset(Dataset):\n",
    "    def __init__(self, data, input_vocab, output_vocab):\n",
    "        self.input_lang = Lang(input_vocab)\n",
    "        self.target_lang = Lang(output_vocab)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.encoder_inputs = [self.input_lang.str_to_ind(input_sent) for input_sent, _ in self.data]\n",
    "\n",
    "        targets = [self.target_lang.str_to_ind(target_sent) for _, target_sent in self.data]\n",
    "        self.decoder_inputs = [target[:-1] for target in targets]\n",
    "        self.decoder_targets = [target[1:] for target in targets]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationTrainingDataset(train_data, human_vocab, machine_vocab)\n",
    "val_dataset = TranslationTrainingDataset(val_data, human_vocab, machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 4, 14, 4, 14, 12] 4/9/97\n",
      "[1, 5, 13, 13, 11, 3, 4, 8, 3, 4, 13] >1997-04-09\n",
      "[5, 13, 13, 11, 3, 4, 8, 3, 4, 13, 2] 1997-04-09<\n"
     ]
    }
   ],
   "source": [
    "x,y,z = train_dataset[0]\n",
    "print(x, train_dataset.input_lang.ind_to_str(x))\n",
    "print(y, train_dataset.target_lang.ind_to_str(y))\n",
    "print(z, train_dataset.target_lang.ind_to_str(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    batch = []\n",
    "    for i in range(len(data[0])):\n",
    "        batch_data = [torch.tensor(item[i], dtype=torch.int64) for item in data]\n",
    "        batch_data = nn.utils.rnn.pad_sequence(batch_data, batch_first=True)\n",
    "        batch.append(batch_data)\n",
    "\n",
    "\n",
    "    return tuple(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8)\n",
    "val_loader = DataLoader(dataset=val_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderGRU(\n",
      "  (embedding): Embedding(37, 32)\n",
      "  (gru): GRU(32, 64, batch_first=True)\n",
      ")\n",
      "torch.Size([64, 6, 64]) torch.Size([1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x_enc_batch,  x_dec_batch, y_batch = next(iter(train_loader))\n",
    "# print(x_enc_batch)\n",
    "# print(x_dec_batch)\n",
    "# print(y_batch)\n",
    "encoder = EncoderGRU(len(human_vocab), hidden_size=64, embedding_dim=32, num_layers=1, bidirectional=False)\n",
    "print(encoder)\n",
    "enc_out, enc_hidden = encoder(x_enc_batch)\n",
    "print(enc_out.shape, enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/9/97\n",
      "9/8/83\n",
      "8/7/97\n",
      "4/2/02\n",
      "1/9/12\n",
      "7/3/09\n",
      "9/9/84\n",
      "2/2/00\n",
      "1/1/79\n",
      "4/7/92\n",
      "8/7/81\n",
      "8/3/80\n",
      "6/7/07\n",
      "7/3/09\n",
      "1/8/95\n",
      "1/2/71\n",
      "7/2/00\n",
      "8/4/98\n",
      "4/3/78\n",
      "7/3/95\n",
      "8/5/91\n",
      "8/9/83\n",
      "8/5/04\n",
      "8/5/18\n",
      "9/4/14\n",
      "1/3/21\n",
      "7/9/97\n",
      "6/3/88\n",
      "2/2/84\n",
      "4/2/82\n",
      "6/2/97\n",
      "9/2/18\n",
      "2/1/07\n",
      "3/5/70\n",
      "3/2/07\n",
      "4/7/21\n",
      "7/7/99\n",
      "6/9/87\n",
      "5/7/14\n",
      "2/5/71\n",
      "9/1/92\n",
      "5/2/00\n",
      "8/1/74\n",
      "2/9/05\n",
      "6/6/07\n",
      "5/6/93\n",
      "1/5/11\n",
      "3/7/90\n",
      "6/4/94\n",
      "1/5/10\n",
      "5/8/21\n",
      "7/2/11\n",
      "6/3/91\n",
      "3/4/76\n",
      "8/4/07\n",
      "2/8/23\n",
      "7/6/73\n",
      "2/5/19\n",
      "9/5/04\n",
      "4/5/71\n",
      "8/1/01\n",
      "3/7/80\n",
      "2/2/13\n",
      "6/1/02\n"
     ]
    }
   ],
   "source": [
    "lang = train_dataset.input_lang\n",
    "for row in x_enc_batch:\n",
    "    print(lang.ind_to_str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderGRU(\n",
      "  (embedding): Embedding(14, 32)\n",
      "  (gru): GRU(32, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=14, bias=True)\n",
      ")\n",
      "EncoderGRU(\n",
      "  (embedding): Embedding(37, 32)\n",
      "  (gru): GRU(32, 64, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderGRU(len(human_vocab), hidden_size=64, embedding_dim=32, num_layers=1, bidirectional=False)\n",
    "decoder = DecoderGRU(len(machine_vocab), hidden_size=64, embedding_dim=32, num_layers=1)\n",
    "print(decoder)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder forward pass\n",
      "\n",
      "Training with teacher forcing\n",
      "Input batch shape: torch.Size([64, 11])\n",
      "decoder output shape: torch.Size([64, 11, 14])\n",
      "decoder hn shape: torch.Size([1, 64, 64])\n",
      "\n",
      "Training without teacher forcing\n",
      "Decoder 1st input shape: torch.Size([64, 1])\n",
      "decoder output shape: torch.Size([64, 1, 14])\n",
      "decoder hn shape: torch.Size([1, 64, 64])\n",
      "decoder 2nd input shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder forward pass\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Input batch shape: {x_dec_batch.shape}\")\n",
    "dec_out, dec_hid = decoder(x_dec_batch, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "# loss(dec_out, target)\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training without teacher forcing\")\n",
    "dec_input = x_dec_batch[:,0:1]\n",
    "print(f\"Decoder 1st input shape: {dec_input.shape}\")\n",
    "dec_out, dec_hid = decoder(dec_input, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "next_input = torch.argmax(dec_out, dim=-1)\n",
    "print(f\"decoder 2nd input shape: {next_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2seq(\n",
       "  (encoder): EncoderGRU(\n",
       "    (embedding): Embedding(37, 32)\n",
       "    (gru): GRU(32, 64, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderGRU(\n",
       "    (embedding): Embedding(14, 32)\n",
       "    (gru): GRU(32, 64, batch_first=True)\n",
       "    (fc): Linear(in_features=64, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2seq(encoder, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward pass (input -> encoder -> decoder -> output)\n",
      "\n",
      "Training without teacher forcing (out_length = 20)\n",
      "Input batch shape: torch.Size([64, 6])\n",
      "Output shape: torch.Size([64, 20, 14])\n",
      "\n",
      "Training with teacher forcing\n",
      "Encoder input batch shape: torch.Size([64, 6])\n",
      "Decoder input batch shape: torch.Size([64, 11])\n",
      "Output shape: torch.Size([64, 11, 14])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model forward pass (input -> encoder -> decoder -> output)\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training without teacher forcing (out_length = 20)\")\n",
    "print(f\"Input batch shape: {x_enc_batch.shape}\")\n",
    "output =  model(x_enc_batch, out_length = 20)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Encoder input batch shape: {x_enc_batch.shape}\")\n",
    "print(f\"Decoder input batch shape: {x_dec_batch.shape}\")\n",
    "output = model(x_enc_batch, dec_input_batch = x_dec_batch, teacher_forcing = True)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "trainer = Trainer(model, train_dataLoader=train_loader, val_dataLoader=val_loader, loss_fn= cross_entropy_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1    training loss: 1.764870 | validation loss: 1.473958\n",
      "Epoch  2    training loss: 1.107737 | validation loss: 0.959201\n",
      "Epoch  3    training loss: 0.822331 | validation loss: 0.851810\n",
      "Epoch  4    training loss: 0.719037 | validation loss: 0.766839\n",
      "Epoch  5    training loss: 0.659734 | validation loss: 0.711376\n",
      "Epoch  6    training loss: 0.632986 | validation loss: 0.691685\n",
      "Epoch  7    training loss: 0.616020 | validation loss: 0.684957\n",
      "Epoch  8    training loss: 0.606244 | validation loss: 0.689338\n",
      "Epoch  9    training loss: 0.600491 | validation loss: 0.679058\n",
      "Epoch  10   training loss: 0.598975 | validation loss: 0.673430\n",
      "Epoch  11   training loss: 0.590169 | validation loss: 0.657714\n",
      "Epoch  12   training loss: 0.576176 | validation loss: 0.629070\n",
      "Epoch  13   training loss: 0.567702 | validation loss: 0.618632\n",
      "Epoch  14   training loss: 0.559543 | validation loss: 0.605172\n",
      "Epoch  15   training loss: 0.543017 | validation loss: 0.572176\n",
      "Epoch  16   training loss: 0.519836 | validation loss: 0.543780\n",
      "Epoch  17   training loss: 0.495915 | validation loss: 0.541793\n",
      "Epoch  18   training loss: 0.485120 | validation loss: 0.522418\n",
      "Epoch  19   training loss: 0.467526 | validation loss: 0.522608\n",
      "Epoch  20   training loss: 0.462636 | validation loss: 0.502999\n",
      "Epoch  21   training loss: 0.449911 | validation loss: 0.496749\n",
      "Epoch  22   training loss: 0.430801 | validation loss: 0.485693\n",
      "Epoch  23   training loss: 0.407066 | validation loss: 0.475347\n",
      "Epoch  24   training loss: 0.383604 | validation loss: 0.422055\n",
      "Epoch  25   training loss: 0.350019 | validation loss: 0.376650\n",
      "Epoch  26   training loss: 0.313326 | validation loss: 0.343015\n",
      "Epoch  27   training loss: 0.286137 | validation loss: 0.300519\n",
      "Epoch  28   training loss: 0.262012 | validation loss: 0.272390\n",
      "Epoch  29   training loss: 0.241793 | validation loss: 0.256702\n",
      "Epoch  30   training loss: 0.220378 | validation loss: 0.240910\n",
      "Epoch  31   training loss: 0.205704 | validation loss: 0.231792\n",
      "Epoch  32   training loss: 0.196104 | validation loss: 0.213838\n",
      "Epoch  33   training loss: 0.182889 | validation loss: 0.206748\n",
      "Epoch  34   training loss: 0.177256 | validation loss: 0.198865\n",
      "Epoch  35   training loss: 0.165361 | validation loss: 0.192712\n",
      "Epoch  36   training loss: 0.159412 | validation loss: 0.185749\n",
      "Epoch  37   training loss: 0.150246 | validation loss: 0.194249\n",
      "Epoch  38   training loss: 0.147969 | validation loss: 0.184242\n",
      "Epoch  39   training loss: 0.134543 | validation loss: 0.175226\n",
      "Epoch  40   training loss: 0.127550 | validation loss: 0.164864\n",
      "Epoch  41   training loss: 0.117839 | validation loss: 0.171288\n",
      "Epoch  42   training loss: 0.120084 | validation loss: 0.152466\n",
      "Epoch  43   training loss: 0.112764 | validation loss: 0.143192\n",
      "Epoch  44   training loss: 0.108463 | validation loss: 0.154559\n",
      "Epoch  45   training loss: 0.115138 | validation loss: 0.153017\n",
      "Epoch  46   training loss: 0.096726 | validation loss: 0.110423\n",
      "Epoch  47   training loss: 0.091775 | validation loss: 0.099254\n",
      "Epoch  48   training loss: 0.078759 | validation loss: 0.092680\n",
      "Epoch  49   training loss: 0.074800 | validation loss: 0.096578\n",
      "Epoch  50   training loss: 0.064947 | validation loss: 0.086601\n"
     ]
    }
   ],
   "source": [
    "trainer.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translations(model, n = 10):\n",
    "    test_loader = DataLoader(dataset=val_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8, shuffle=True)\n",
    "\n",
    "    x, z, y = next(iter(test_loader))\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    z = z.to(device)\n",
    "\n",
    "    y_hat = model(\n",
    "            x,\n",
    "            teacher_forcing=False,\n",
    "            sos_index=1,\n",
    "            out_length=11,\n",
    "        )\n",
    "\n",
    "    input_lang = train_dataset.input_lang\n",
    "    output_lang = train_dataset.target_lang\n",
    "\n",
    "    y_hat = y_hat.argmax(axis=-1)\n",
    "\n",
    "    print(\"Translation test\\n\")\n",
    "    print(\"Input                 |   Machine translation | Correct translation\")\n",
    "    for i in range(10):\n",
    "        print(input_lang.ind_to_str(x[i]).replace(';', ' '), output_lang.ind_to_str(y_hat[i]).strip('<>;'), \" \"*10, output_lang.ind_to_str(y[i]).strip(';<>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation test\n",
      "\n",
      "Input                 |   Machine translation | Correct translation\n",
      "4 nov 1978                  1978-11-24            1978-11-04\n",
      "26 feb 1978                 1978-03-22            1978-02-26\n",
      "tuesday november 11 2003    2003-11-11            2003-11-11\n",
      "15 nov 1994                 1994-11-10            1994-11-15\n",
      "18 may 2011                 2011-01-28            2011-05-18\n",
      "06 feb 1981                 1982-12-06            1981-02-06\n",
      "26 apr 1985                 1985-04-26            1985-04-26\n",
      "friday april 7 2017         2017-04-07            2017-04-07\n",
      "3 august 1992               1992-08-03            1992-08-03\n",
      "thursday june 29 2023       2023-06-29            2023-06-29\n"
     ]
    }
   ],
   "source": [
    "print_translations(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        \n",
    "        print(scores.shape)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 14])\n",
      "torch.Size([5, 1, 32]) torch.Size([5, 1, 14])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 32\n",
    "output_size = len(machine_vocab)\n",
    "batch_size = 5\n",
    "\n",
    "\n",
    "att = BahdanauAttention(hidden_size)\n",
    "\n",
    "hidden = torch.zeros(1, batch_size, hidden_size)\n",
    "keys = torch.zeros(batch_size, output_size, hidden_size) # encoder outputs\n",
    "\n",
    "query = hidden.permute(1, 0, 2)\n",
    "\n",
    "c, w = att(query, keys)\n",
    "print(c.shape, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(AttentionDecoderGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, sos_index = 1, decoder_input = None, teacher_forcing = False, out_length = 1):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(sos_index)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(out_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if teacher_forcing:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = decoder_input[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        # input_gru = torch.cat((embedded, context), dim=2)\n",
    "        input_gru = context\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionSeq2seq(nn.Module):\n",
    "    def __init__(self, encoder: EncoderGRU, decoder: AttentionDecoderGRU) -> None:\n",
    "        super(Seq2seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_input_batch, sos_index = 1, decoder_input = None, teacher_forcing = False, out_length = 1):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(enc_input_batch)\n",
    "        batch_size = len(enc_input_batch)\n",
    "        \n",
    "        decoder_output, _, _ = decoder(encoder_outputs, encoder_hidden, sos_index, decoder_input, teacher_forcing, out_length)\n",
    "        \n",
    "        return decoder_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
